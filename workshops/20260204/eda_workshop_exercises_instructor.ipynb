{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Workshop\n",
    "## The Bridge Between Raw Data and Meaningful Insight\n",
    "\n",
    "**Dataset:** Respiratory Patient Data (OMOP CDM Synthetic Extract)\n",
    "\n",
    "**INSTRUCTOR VERSION - WITH SOLUTIONS**\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this workshop, you will be able to:\n",
    "1. Distinguish between seven types of analytical questions and understand their EDA requirements\n",
    "2. Apply the four dimensions of exploration (distributional, relational, structural, comparative)\n",
    "3. Identify data quality issues, patterns, and limitations before modeling\n",
    "4. Interpret findings and distinguish signal from artifact\n",
    "5. Determine appropriate next steps based on EDA outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup and Imports\n",
    "\n",
    "Run the cell below to import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Initialize random number generator for reproducibility, Panda's utilizes NumPy module not \"random\"\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Data Loading and Initial Inspection\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "This dataset contains synthetic patient records extracted from an OMOP Common Data Model (from OHDSI). The records represent patients with respiratory observations, including:\n",
    "- Patient demographics (age, gender, race, ethnicity)\n",
    "- Visit information (dates, type, conditions)\n",
    "- Vital signs (temperature, oxygen saturation, heart rate, etc.)\n",
    "- Vaccination history\n",
    "- Patient outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intial Analysis\n",
    "With any dataset, you'll want to perform an initial \"exploratory\" data analysis to help you understand the structure, patterns, and relationships.\n",
    "\n",
    "A few goals:\n",
    "1. **Data Summarization** - gain an quick overview of the dataset\n",
    "   - **Shape and size of data:** Number of rows, columns, and unique values.\n",
    "   - **Descriptive statistics:** Mean, median, standard deviation, percentiles.\n",
    "2. **Data Cleaning** - ensure data quality\n",
    "   - **Handling missing values:** Identify and impute (mean/median/mode) or remove missing entries.\n",
    "   - **Removing duplicates:** Eliminate redundant rows or records.\n",
    "   - **Correcting data types:** Convert data to appropriate formats (e.g., dates, numbers, categories).\n",
    "   - **Dealing with outliers:** Detect and decide whether to remove or transform extreme values.\n",
    "3. **Feature Engineering - add additional features/variables to support analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Files and Establish Starting Dataframes\n",
    "filename = 'data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform basic exploratory data analysis\n",
    "# df.head(n)  # top n rows, n defaults to 5\n",
    "# df.tail(n)  # last n rows\n",
    "# df.sample(5) # sample x rows\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataframe shape:\",df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataframe shape:\",df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date fields\n",
    "for c in [\"visit_start_date\", \"visit_end_date\", \"birth_datetime\", \"measurement_Date\",\"flu_last_administered\",\"tdap_last_administered\",\"mmr_last_administered\",\"polio_last_administered\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine missing fields\n",
    "n_rows = len(df)\n",
    "\n",
    "missing_table = (   # create a new dataframe\n",
    "    df.isna()\n",
    "      .agg(['sum', 'mean'])\n",
    "      .T\n",
    "      .rename(columns={'sum': 'missing_count', 'mean': 'missing_percent'})\n",
    ")\n",
    "\n",
    "missing_table['missing_percent'] = (missing_table['missing_percent'] * 100).round(2)\n",
    "missing_table['non_missing_count'] = n_rows - missing_table['missing_count']\n",
    "missing_table['dtype'] = df.dtypes.astype(str)\n",
    "\n",
    "missing_table = (\n",
    "    missing_table\n",
    "      .reset_index(names='column')\n",
    "      .sort_values(by=['missing_percent', 'column'], ascending=[False, True])\n",
    "      .set_index('column')\n",
    ")\n",
    "\n",
    "missing_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What patterns do you notice in the missing data? Which columns have the most missing values, and why might that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column for visit length - ignoring visit type\n",
    "los = (df[\"visit_end_date\"] - df[\"visit_start_date\"]).dt.days\n",
    "df[\"length_of_stay_days\"] = los.clip(lower=0)\n",
    "\n",
    "\n",
    "# Modify labels for deceased column\n",
    "df[\"deceased_flag\"] = df[\"deceased\"].map({\"Y\": \"Deceased\", \"N\": \"Alive\"}).fillna(\"Unknown\").astype(\"category\")\n",
    "\n",
    "# columns for year and month\n",
    "df[\"visit_year\"] = df[\"visit_start_date\"].dt.year\n",
    "df[\"visit_month\"] = df[\"visit_start_date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "df['gender_source_value'] = df['gender_source_value'].astype('category')\n",
    "df['race_source_value'] = df['race_source_value'].astype('category')\n",
    "df['ethnicity_source_value'] = df['ethnicity_source_value'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics for Numeric Columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for categorical columns\n",
    "df.describe(include=['object','category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an alternate view of the conditions, placingin into a separate tidy dataframe\n",
    "import re\n",
    "\n",
    "# robust split on \":\" allowing extra spaces; keep NaN if empty\n",
    "def split_conditions(s):\n",
    "    if pd.isna(s) or str(s).strip() == \"\":\n",
    "        return []\n",
    "    # split on \":\" with optional surrounding spaces\n",
    "    parts = re.split(r\"\\s*:\\s*\", str(s))\n",
    "    # normalize: strip, drop empties, lower (or title-case if you prefer)\n",
    "    parts = [p.strip() for p in parts if p and p.strip()]\n",
    "    return parts\n",
    "\n",
    "# apply once to create a list-typed column\n",
    "df[\"condition_list\"] = df[\"condition\"].map(split_conditions)\n",
    "\n",
    "cond_long = (\n",
    "    df[[\"visit_occurrence_id\", \"person_id\", \"visit_start_date\"]]\n",
    "      .assign(condition_item=df[\"condition_list\"])\n",
    "      .explode(\"condition_item\", ignore_index=True)\n",
    ")\n",
    "\n",
    "# drop rows where no condition exists after cleaning\n",
    "cond_long = cond_long.dropna(subset=[\"condition_item\"])\n",
    "\n",
    "# (optional) dedupe within visit in case the same condition appears twice\n",
    "cond_long = cond_long.drop_duplicates(subset=[\"visit_occurrence_id\", \"condition_item\"])\n",
    "cond_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For outpatient visits, assume this is a data issue and the length should be 0\n",
    "is_outpatient = df['visit_type'].astype(str).str.contains('outpatient', case=False, na=False)\n",
    "\n",
    "# align dates, then recompute LOS as zero\n",
    "df.loc[is_outpatient, 'visit_end_date'] = df.loc[is_outpatient, 'visit_start_date']\n",
    "df.loc[is_outpatient, 'length_of_stay_days'] = 0\n",
    "\n",
    "# remove any records where length_of_stay_days > 100\n",
    "df = df[df[\"length_of_stay_days\"] <= 100].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Distributional Exploration\n",
    "\n",
    "**Goal:** Examine individual variables to understand their scale, shape, and validity.\n",
    "\n",
    "### The Seven Question Types\n",
    "\n",
    "Before we explore, remember that the type of question determines the EDA approach:\n",
    "\n",
    "| Type | Core Question | Example |\n",
    "|------|--------------|--------|\n",
    "| Descriptive | What happened? | What is the distribution of conditions? |\n",
    "| Exploratory | What patterns exist? | Is there a relationship between temperature and O2 sat? |\n",
    "| Inferential | Does this generalize? | Is the O2 sat difference statistically significant? |\n",
    "| Predictive | What will happen? | Can we predict inpatient admission? |\n",
    "| Prescriptive | What should we do? | What thresholds should trigger escalation? |\n",
    "| Causal | What if we intervene? | Would earlier vaccination reduce severity? |\n",
    "| Mechanistic | What process produces this? | How does symptom progression unfold? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Demographic Distributions\n",
    "\n",
    "Create frequency counts for the following categorical variables:\n",
    "1. Gender (`gender_source_value`)\n",
    "2. Race (`race_source_value`)\n",
    "3. Ethnicity (`ethnicity_source_value`)\n",
    "\n",
    "**Note:** For demographics, we should look at unique patients, not all visits (since one patient can have multiple visits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a dataframe of unique patients\n",
    "patients = df.drop_duplicates(subset='person_id')\n",
    "\n",
    "print(f\"Total unique patients: {len(patients)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distribution\n",
    "gender_counts = patients['gender_source_value'].value_counts()\n",
    "print(\"\\nGender Distribution:\")\n",
    "print(gender_counts)\n",
    "print(f\"\\nPercentages:\")\n",
    "print(patients['gender_source_value'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Race distribution\n",
    "race_counts = patients['race_source_value'].value_counts()\n",
    "print(\"\\nRace Distribution:\")\n",
    "print(race_counts)\n",
    "print(f\"\\nPercentages:\")\n",
    "print(patients['race_source_value'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethnicity distribution\n",
    "ethnicity_counts = patients['ethnicity_source_value'].value_counts()\n",
    "print(\"\\nEthnicity Distribution:\")\n",
    "print(ethnicity_counts)\n",
    "print(f\"\\nPercentages:\")\n",
    "print(patients['ethnicity_source_value'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Age Distribution\n",
    "\n",
    "1. Calculate descriptive statistics for `age_at_visit_years`\n",
    "2. Create a histogram of the age distribution\n",
    "3. Create age groups (Pediatric: 0-18, Young Adult: 18-40, Middle Age: 40-65, Elderly: 65+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Descriptive statistics for age\n",
    "print(\"Age Descriptive Statistics:\")\n",
    "print(df['age_at_visit_years'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Histogram of age distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['age_at_visit_years'].dropna(), bins=30, edgecolor='black')\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Age Distribution at Visit')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create age groups and show their distribution\n",
    "df['age_group'] = pd.cut(df['age_at_visit_years'],\n",
    "                         bins=[0, 18, 40, 65, 100],\n",
    "                         labels=['Pediatric', 'Young Adult', 'Middle Age', 'Elderly'])\n",
    "\n",
    "age_group_counts = df['age_group'].value_counts().sort_index()\n",
    "print(\"\\nAge Group Distribution:\")\n",
    "print(age_group_counts)\n",
    "print(\"\\nPercentages:\")\n",
    "print(df['age_group'].value_counts(normalize=True).sort_index() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Condition Analysis\n",
    "\n",
    "The `condition` column contains multiple conditions separated by colons (`:`).\n",
    "\n",
    "1. Parse the conditions into individual items\n",
    "2. Count the frequency of each condition\n",
    "3. Create a bar chart of the top 10 conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parse conditions (split by colon) - already done earlier, but repeating here\n",
    "df['condition_list'] = df['condition'].str.split(':')\n",
    "\n",
    "# 2. Explode and count\n",
    "all_conditions = df['condition_list'].explode()\n",
    "all_conditions = all_conditions.str.strip()  # Remove whitespace\n",
    "condition_counts = all_conditions.value_counts()\n",
    "\n",
    "print(\"Top 10 Conditions:\")\n",
    "print(condition_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Bar chart of top 10 conditions\n",
    "plt.figure(figsize=(12, 6))\n",
    "condition_counts.head(10).plot(kind='barh')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Condition')\n",
    "plt.title('Top 10 Most Common Conditions')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4: Vital Signs Distribution (COVID-Suspected Patients)\n",
    "\n",
    "Many vital signs are only recorded for COVID-suspected visits.\n",
    "\n",
    "1. Filter the data to only COVID-suspected patients (`observation_source == 'Suspected COVID-19'`)\n",
    "2. Calculate descriptive statistics for the vital signs columns\n",
    "3. Create histograms for oxygen saturation, respiratory rate, heart rate, and body temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter to COVID-suspected patients\n",
    "covid_df = df[df['observation_source'] == 'Suspected COVID-19']\n",
    "\n",
    "print(f\"COVID-suspected visits: {len(covid_df)}\")\n",
    "print(f\"Total visits: {len(df)}\")\n",
    "print(f\"Percentage: {len(covid_df)/len(df)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Descriptive statistics for vital signs\n",
    "vital_cols = ['oxygen_saturation_percent', 'respiratory_rate_per_minute',\n",
    "              'heart_rate_bpm', 'body_temperature_c', 'systolic', 'diastolic']\n",
    "\n",
    "print(\"Vital Signs Descriptive Statistics (COVID-Suspected Patients):\")\n",
    "print(covid_df[vital_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create histograms (2x2 subplot)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Oxygen saturation\n",
    "axes[0, 0].hist(covid_df['oxygen_saturation_percent'].dropna(), bins=30, edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Oxygen Saturation (%)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Oxygen Saturation Distribution')\n",
    "axes[0, 0].axvline(95, color='red', linestyle='--', label='Normal threshold')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Respiratory rate\n",
    "axes[0, 1].hist(covid_df['respiratory_rate_per_minute'].dropna(), bins=30, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Respiratory Rate (per minute)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Respiratory Rate Distribution')\n",
    "\n",
    "# Heart rate\n",
    "axes[1, 0].hist(covid_df['heart_rate_bpm'].dropna(), bins=30, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Heart Rate (bpm)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Heart Rate Distribution')\n",
    "\n",
    "# Body temperature\n",
    "axes[1, 1].hist(covid_df['body_temperature_c'].dropna(), bins=30, edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Body Temperature (°C)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Body Temperature Distribution')\n",
    "axes[1, 1].axvline(38, color='red', linestyle='--', label='Fever threshold')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Are there any concerning values in the vital signs? What might explain extreme values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Instructor notes:*\n",
    "\n",
    "Students should identify:\n",
    "- Oxygen saturation values below 90% (hypoxemia) and especially below 80% (severe hypoxemia)\n",
    "- Extremely high or low temperatures that may indicate data entry errors or critical conditions\n",
    "- Very high heart rates (>180 bpm) or respiratory rates (>40/min) that may be artifacts or represent critical illness\n",
    "- Some extreme values may be biologically implausible and could indicate measurement errors or data quality issues\n",
    "- The distribution of values should be discussed in terms of clinical significance vs. data quality concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.5: Visit Type Distribution\n",
    "\n",
    "1. Count the number of Inpatient vs Outpatient visits\n",
    "2. Calculate the percentage of each type\n",
    "3. Create a pie chart or bar chart showing the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-2. Count and percentage\n",
    "visit_type_counts = df['visit_type'].value_counts()\n",
    "visit_type_pct = df['visit_type'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Visit Type Distribution:\")\n",
    "print(visit_type_counts)\n",
    "print(\"\\nPercentages:\")\n",
    "print(visit_type_pct)\n",
    "\n",
    "# 3. Create visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "visit_type_counts.plot(kind='bar', ax=axes[0], color=['skyblue', 'lightcoral'])\n",
    "axes[0].set_xlabel('Visit Type')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Visit Type Distribution (Bar Chart)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(visit_type_counts, labels=visit_type_counts.index, autopct='%1.1f%%',\n",
    "            colors=['skyblue', 'lightcoral'], startangle=90)\n",
    "axes[1].set_title('Visit Type Distribution (Pie Chart)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.6: Outlier Detection in Vital Signs\n",
    "\n",
    "Identify potential outliers in vital sign measurements. Consider clinical validity:\n",
    "- Temperature: Normal 36-37.5°C, fever >38°C, extreme >42°C\n",
    "- Oxygen saturation: Normal >95%, concerning <90%, critical <80%\n",
    "- Heart rate: Normal 60-100 bpm, tachycardia >100, extreme >180\n",
    "- Respiratory rate: Normal 12-20/min, elevated >24, extreme >40\n",
    "\n",
    "**Dimension focus:** Distributional exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers based on clinical thresholds\n",
    "outlier_summary = pd.DataFrame({\n",
    "    'Vital Sign': ['Temperature', 'Oxygen Saturation', 'Heart Rate', 'Respiratory Rate'],\n",
    "    'Extreme (count)': [\n",
    "        (covid_df['body_temperature_c'] > 42).sum(),\n",
    "        (covid_df['oxygen_saturation_percent'] < 80).sum(),\n",
    "        (covid_df['heart_rate_bpm'] > 180).sum(),\n",
    "        (covid_df['respiratory_rate_per_minute'] > 40).sum()\n",
    "    ],\n",
    "    'Concerning (count)': [\n",
    "        ((covid_df['body_temperature_c'] > 38) & (covid_df['body_temperature_c'] <= 42)).sum(),\n",
    "        ((covid_df['oxygen_saturation_percent'] < 90) & (covid_df['oxygen_saturation_percent'] >= 80)).sum(),\n",
    "        ((covid_df['heart_rate_bpm'] > 100) & (covid_df['heart_rate_bpm'] <= 180)).sum(),\n",
    "        ((covid_df['respiratory_rate_per_minute'] > 24) & (covid_df['respiratory_rate_per_minute'] <= 40)).sum()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Outlier Analysis for Vital Signs:\")\n",
    "print(outlier_summary)\n",
    "\n",
    "# Show some extreme cases\n",
    "print(\"\\nExtreme Temperature Cases:\")\n",
    "extreme_temp = covid_df[covid_df['body_temperature_c'] > 42][['person_id', 'body_temperature_c', 'deceased']]\n",
    "print(extreme_temp.head())\n",
    "\n",
    "print(\"\\nCritical Oxygen Saturation Cases:\")\n",
    "critical_o2 = covid_df[covid_df['oxygen_saturation_percent'] < 80][['person_id', 'oxygen_saturation_percent', 'deceased']]\n",
    "print(critical_o2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Relational Exploration\n",
    "\n",
    "**Goal:** Investigate how multiple variables interact rather than treating them in isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Correlation Matrix\n",
    "\n",
    "Create a correlation matrix heatmap for the numeric vital sign variables using the COVID-suspected patient data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for correlation\n",
    "numeric_cols = ['age_at_visit_years', 'oxygen_saturation_percent',\n",
    "                'respiratory_rate_per_minute', 'heart_rate_bpm',\n",
    "                'body_temperature_c', 'systolic', 'diastolic']\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = covid_df[numeric_cols].corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Vital Signs and Age')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStrongest correlations (absolute value > 0.3):\")\n",
    "# Get upper triangle of correlation matrix\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "corr_pairs = corr_matrix.where(mask).stack().sort_values(ascending=False)\n",
    "strong_corr = corr_pairs[abs(corr_pairs) > 0.3]\n",
    "print(strong_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What correlations do you observe? Are any surprising or concerning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Instructor notes:*\n",
    "\n",
    "Students should identify:\n",
    "- Systolic and diastolic blood pressure are highly correlated (expected)\n",
    "- Negative correlation between oxygen saturation and respiratory rate (hypoxic patients breathe faster)\n",
    "- Weak or no correlation between some variables may indicate independence or non-linear relationships\n",
    "- Age correlations with vital signs may reveal age-related physiological patterns\n",
    "- Discuss whether observed correlations are clinically meaningful or potential confounders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Temperature vs Oxygen Saturation\n",
    "\n",
    "Create a scatter plot examining the relationship between body temperature and oxygen saturation. Color the points by the `deceased` status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data with both measurements\n",
    "temp_o2_data = covid_df.dropna(subset=['body_temperature_c', 'oxygen_saturation_percent', 'deceased'])\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = {'Y': 'red', 'N': 'blue'}\n",
    "for deceased_status, group in temp_o2_data.groupby('deceased'):\n",
    "    plt.scatter(group['body_temperature_c'], group['oxygen_saturation_percent'],\n",
    "                c=colors[deceased_status], label=f\"Deceased: {deceased_status}\",\n",
    "                alpha=0.5, s=30)\n",
    "\n",
    "plt.xlabel('Body Temperature (°C)')\n",
    "plt.ylabel('Oxygen Saturation (%)')\n",
    "plt.title('Relationship between Body Temperature and Oxygen Saturation')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=95, color='green', linestyle='--', alpha=0.5, label='Normal O2 threshold')\n",
    "plt.axvline(x=38, color='orange', linestyle='--', alpha=0.5, label='Fever threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Condition Count and Vital Signs\n",
    "\n",
    "1. Create a variable `condition_count` that counts the number of conditions per visit (count the colons + 1)\n",
    "2. Compare the mean vital signs between patients with 1-2 conditions vs 3+ conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create condition count\n",
    "df['condition_count'] = df['condition'].str.count(':') + 1\n",
    "\n",
    "# Check the distribution\n",
    "print(\"Condition Count Distribution:\")\n",
    "print(df['condition_count'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compare vital signs by condition severity (1-2 vs 3+)\n",
    "# First add condition_count to covid_df\n",
    "covid_df = covid_df.copy()\n",
    "covid_df['condition_count'] = covid_df['condition'].str.count(':') + 1\n",
    "covid_df['high_condition_count'] = covid_df['condition_count'] >= 3\n",
    "\n",
    "# Compare vital signs\n",
    "vital_comparison = covid_df.groupby('high_condition_count')[vital_cols].mean()\n",
    "print(\"\\nMean Vital Signs by Condition Severity:\")\n",
    "print(vital_comparison)\n",
    "\n",
    "# Calculate differences\n",
    "print(\"\\nDifference (3+ conditions minus 1-2 conditions):\")\n",
    "difference = vital_comparison.loc[True] - vital_comparison.loc[False]\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4: Visit Type and Vital Signs\n",
    "\n",
    "Compare vital signs between Inpatient and Outpatient visits. Create box plots showing the distribution of oxygen saturation by visit type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for oxygen saturation by visit type\n",
    "plt.figure(figsize=(10, 6))\n",
    "covid_df.boxplot(column='oxygen_saturation_percent', by='visit_type', figsize=(10, 6))\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.title('Oxygen Saturation Distribution by Visit Type')\n",
    "plt.xlabel('Visit Type')\n",
    "plt.ylabel('Oxygen Saturation (%)')\n",
    "plt.axhline(y=95, color='red', linestyle='--', alpha=0.5, label='Normal threshold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nOxygen Saturation Statistics by Visit Type:\")\n",
    "print(covid_df.groupby('visit_type')['oxygen_saturation_percent'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.5: Deceased Status and Vital Signs\n",
    "\n",
    "1. Calculate the mean and median vital signs grouped by deceased status (Y/N)\n",
    "2. Create box plots comparing oxygen saturation between deceased and non-deceased patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Mean/median vital signs by deceased status\n",
    "deceased_vital_stats = covid_df.groupby('deceased')[vital_cols].agg(['mean', 'median'])\n",
    "print(\"Vital Signs by Deceased Status:\")\n",
    "print(deceased_vital_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Box plots for oxygen saturation by deceased status\n",
    "plt.figure(figsize=(10, 6))\n",
    "covid_df.boxplot(column='oxygen_saturation_percent', by='deceased', figsize=(10, 6))\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.title('Oxygen Saturation Distribution by Deceased Status')\n",
    "plt.xlabel('Deceased (Y/N)')\n",
    "plt.ylabel('Oxygen Saturation (%)')\n",
    "plt.axhline(y=95, color='red', linestyle='--', alpha=0.5, label='Normal threshold')\n",
    "plt.axhline(y=90, color='orange', linestyle='--', alpha=0.5, label='Concerning threshold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Alternative: side-by-side violin plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=covid_df, x='deceased', y='oxygen_saturation_percent')\n",
    "plt.title('Oxygen Saturation Distribution by Deceased Status (Violin Plot)')\n",
    "plt.xlabel('Deceased (Y/N)')\n",
    "plt.ylabel('Oxygen Saturation (%)')\n",
    "plt.axhline(y=95, color='red', linestyle='--', alpha=0.5, label='Normal threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Structural Exploration\n",
    "\n",
    "**Goal:** Analyze temporal, hierarchical, and sequential patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Date Preparation\n",
    "\n",
    "Convert the date columns to datetime format and extract useful components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime (already done in data prep, but repeating for clarity)\n",
    "df['visit_start_date'] = pd.to_datetime(df['visit_start_date'])\n",
    "df['visit_end_date'] = pd.to_datetime(df['visit_end_date'])\n",
    "\n",
    "# Extract year and month\n",
    "df['visit_year'] = df['visit_start_date'].dt.year\n",
    "df['visit_month'] = df['visit_start_date'].dt.to_period('M').astype(str)\n",
    "\n",
    "print(\"Date columns prepared successfully!\")\n",
    "print(f\"\\nDate range: {df['visit_start_date'].min()} to {df['visit_start_date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Temporal Distribution of Visits\n",
    "\n",
    "1. Count the number of visits by year\n",
    "2. For 2020, create a bar chart showing visits by month\n",
    "3. What patterns do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Visits by year\n",
    "visits_by_year = df['visit_year'].value_counts().sort_index()\n",
    "print(\"Visits by Year:\")\n",
    "print(visits_by_year)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "visits_by_year.plot(kind='bar', color='steelblue')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.title('Distribution of Visits by Year')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Bar chart of 2020 visits by month\n",
    "df_2020 = df[df['visit_year'] == 2020]\n",
    "visits_2020_by_month = df_2020['visit_month'].value_counts().sort_index()\n",
    "\n",
    "print(\"\\n2020 Visits by Month:\")\n",
    "print(visits_2020_by_month)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "visits_2020_by_month.plot(kind='bar', color='coral')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.title('Distribution of Visits by Month in 2020')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n3. Pattern observations:\")\n",
    "print(\"- Look for seasonal trends (e.g., respiratory illness peaks in winter)\")\n",
    "print(\"- COVID-19 pandemic impact should be visible in 2020\")\n",
    "print(\"- Sudden spikes or drops may indicate data collection changes or real events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3: Length of Stay Analysis\n",
    "\n",
    "1. Calculate the length of stay (in days) for each visit\n",
    "2. Filter to inpatient visits only\n",
    "3. Calculate descriptive statistics for length of stay\n",
    "4. Create a histogram of length of stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate length of stay (already done in prep, but showing here)\n",
    "df['length_of_stay'] = (df['visit_end_date'] - df['visit_start_date']).dt.days\n",
    "df['length_of_stay'] = df['length_of_stay'].clip(lower=0)  # No negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-4. Inpatient length of stay analysis\n",
    "inpatient_df = df[df['visit_type'].str.contains('Inpatient', na=False)]\n",
    "\n",
    "print(\"Length of Stay Statistics (Inpatient Visits):\")\n",
    "print(inpatient_df['length_of_stay'].describe())\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(inpatient_df['length_of_stay'].dropna(), bins=50, edgecolor='black')\n",
    "plt.xlabel('Length of Stay (days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Length of Stay for Inpatient Visits')\n",
    "plt.axvline(inpatient_df['length_of_stay'].median(), color='red', \n",
    "            linestyle='--', label=f\"Median: {inpatient_df['length_of_stay'].median():.1f} days\")\n",
    "plt.axvline(inpatient_df['length_of_stay'].mean(), color='green', \n",
    "            linestyle='--', label=f\"Mean: {inpatient_df['length_of_stay'].mean():.1f} days\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for outliers\n",
    "print(f\"\\nVisits with LOS > 30 days: {(inpatient_df['length_of_stay'] > 30).sum()}\")\n",
    "print(f\"Visits with LOS > 60 days: {(inpatient_df['length_of_stay'] > 60).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.4: Patient Visit History\n",
    "\n",
    "1. Count the number of visits per patient\n",
    "2. What percentage of patients have multiple visits?\n",
    "3. Find a patient with multiple visits and examine their visit history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Visits per patient\n",
    "visits_per_patient = df.groupby('person_id').size().reset_index(name='visit_count')\n",
    "\n",
    "print(\"Distribution of Visit Counts:\")\n",
    "print(visits_per_patient['visit_count'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Percentage with multiple visits\n",
    "multiple_visits = (visits_per_patient['visit_count'] > 1).sum()\n",
    "total_patients = len(visits_per_patient)\n",
    "pct_multiple = (multiple_visits / total_patients) * 100\n",
    "\n",
    "print(f\"\\nPatients with multiple visits: {multiple_visits} ({pct_multiple:.1f}%)\")\n",
    "print(f\"Patients with single visit: {total_patients - multiple_visits} ({100-pct_multiple:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Examine a patient with multiple visits\n",
    "# Find patient with most visits\n",
    "most_visits_patient = visits_per_patient.loc[visits_per_patient['visit_count'].idxmax(), 'person_id']\n",
    "\n",
    "print(f\"\\nPatient with most visits: {most_visits_patient}\")\n",
    "print(f\"Number of visits: {visits_per_patient[visits_per_patient['person_id'] == most_visits_patient]['visit_count'].values[0]}\")\n",
    "\n",
    "# Show their visit history\n",
    "patient_history = df[df['person_id'] == most_visits_patient][[\n",
    "    'visit_occurrence_id', 'visit_start_date', 'visit_end_date', 'visit_type',\n",
    "    'condition', 'deceased', 'length_of_stay'\n",
    "]].sort_values('visit_start_date')\n",
    "\n",
    "print(\"\\nVisit History:\")\n",
    "print(patient_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.5: Vaccination Timeline Analysis\n",
    "\n",
    "1. Calculate the time between the last flu vaccination and the visit date\n",
    "2. What percentage of patients were vaccinated within the past year (365 days) before their visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate days since flu vaccine\n",
    "df['flu_last_administered'] = pd.to_datetime(df['flu_last_administered'])\n",
    "df['days_since_flu_vaccine'] = (df['visit_start_date'] - df['flu_last_administered']).dt.days\n",
    "\n",
    "print(\"Days Since Flu Vaccine Statistics:\")\n",
    "print(df['days_since_flu_vaccine'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Percentage vaccinated within past year\n",
    "has_vaccine_data = df['days_since_flu_vaccine'].notna()\n",
    "vaccinated_within_year = (df['days_since_flu_vaccine'] <= 365) & (df['days_since_flu_vaccine'] >= 0)\n",
    "\n",
    "total_with_data = has_vaccine_data.sum()\n",
    "vaccinated_count = vaccinated_within_year.sum()\n",
    "pct_vaccinated = (vaccinated_count / total_with_data) * 100 if total_with_data > 0 else 0\n",
    "\n",
    "print(f\"\\nTotal visits with vaccination data: {total_with_data}\")\n",
    "print(f\"Vaccinated within past year: {vaccinated_count} ({pct_vaccinated:.1f}%)\")\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df[df['days_since_flu_vaccine'] >= 0]['days_since_flu_vaccine'].dropna(), \n",
    "         bins=50, edgecolor='black')\n",
    "plt.xlabel('Days Since Last Flu Vaccination')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Time Since Last Flu Vaccination')\n",
    "plt.axvline(365, color='red', linestyle='--', label='1 year')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Comparative Exploration\n",
    "\n",
    "**Goal:** Study differences across groups, time periods, or conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Mortality Rate Comparison\n",
    "\n",
    "1. Calculate the overall mortality rate (percentage with deceased='Y')\n",
    "2. Compare mortality rates by visit type (Inpatient vs Outpatient)\n",
    "3. Compare mortality rates by age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Overall mortality rate\n",
    "overall_mortality_rate = (df['deceased'] == 'Y').mean() * 100\n",
    "print(f\"Overall mortality rate: {overall_mortality_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Mortality by visit type\n",
    "mortality_by_visit = pd.crosstab(\n",
    "    df['visit_type'],\n",
    "    df['deceased'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "print(\"\\nMortality Rate by Visit Type (%):\")\n",
    "print(mortality_by_visit)\n",
    "\n",
    "# Visualization\n",
    "mortality_by_visit['Y'].plot(kind='bar', color='darkred', figsize=(10, 6))\n",
    "plt.title('Mortality Rate by Visit Type')\n",
    "plt.xlabel('Visit Type')\n",
    "plt.ylabel('Mortality Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Mortality by age group\n",
    "# First ensure age_group exists\n",
    "if 'age_group' not in df.columns:\n",
    "    df['age_group'] = pd.cut(df['age_at_visit_years'],\n",
    "                             bins=[0, 18, 40, 65, 100],\n",
    "                             labels=['Pediatric', 'Young Adult', 'Middle Age', 'Elderly'])\n",
    "\n",
    "mortality_by_age = pd.crosstab(\n",
    "    df['age_group'],\n",
    "    df['deceased'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "print(\"\\nMortality Rate by Age Group (%):\")\n",
    "print(mortality_by_age)\n",
    "\n",
    "# Visualization\n",
    "mortality_by_age['Y'].plot(kind='bar', color='darkblue', figsize=(10, 6))\n",
    "plt.title('Mortality Rate by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Mortality Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Visit Type by Age Group\n",
    "\n",
    "Create a cross-tabulation showing what percentage of each age group has Inpatient vs Outpatient visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_by_age = pd.crosstab(\n",
    "    df['age_group'],\n",
    "    df['visit_type'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "print(\"Visit Type Distribution by Age Group (%):\")\n",
    "print(visit_by_age)\n",
    "\n",
    "# Stacked bar chart\n",
    "visit_by_age.plot(kind='bar', stacked=True, figsize=(10, 6), \n",
    "                  color=['lightcoral', 'skyblue'])\n",
    "plt.title('Visit Type Distribution by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.legend(title='Visit Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.3: COVID vs Non-COVID Comparison\n",
    "\n",
    "Compare characteristics between COVID-suspected and non-COVID visits:\n",
    "1. Average age\n",
    "2. Visit type distribution\n",
    "3. Mortality rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a COVID indicator\n",
    "df['is_covid_suspected'] = df['observation_source'] == 'Suspected COVID-19'\n",
    "\n",
    "# Compare the groups\n",
    "covid_summary = df.groupby('is_covid_suspected').agg(\n",
    "    avg_age=('age_at_visit_years', 'mean'),\n",
    "    mortality_rate=('deceased', lambda x: (x == 'Y').mean() * 100),\n",
    "    inpatient_rate=('visit_type', lambda x: (x.str.contains('Inpatient')).mean() * 100),\n",
    "    n_visits=('person_id', 'count')\n",
    ")\n",
    "\n",
    "print(\"COVID-Suspected vs Non-COVID Comparison:\")\n",
    "print(covid_summary)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Average age\n",
    "covid_summary['avg_age'].plot(kind='bar', ax=axes[0], color=['steelblue', 'coral'])\n",
    "axes[0].set_title('Average Age')\n",
    "axes[0].set_xlabel('COVID Suspected')\n",
    "axes[0].set_ylabel('Age (years)')\n",
    "axes[0].set_xticklabels(['No', 'Yes'], rotation=0)\n",
    "\n",
    "# Mortality rate\n",
    "covid_summary['mortality_rate'].plot(kind='bar', ax=axes[1], color=['steelblue', 'coral'])\n",
    "axes[1].set_title('Mortality Rate')\n",
    "axes[1].set_xlabel('COVID Suspected')\n",
    "axes[1].set_ylabel('Mortality Rate (%)')\n",
    "axes[1].set_xticklabels(['No', 'Yes'], rotation=0)\n",
    "\n",
    "# Inpatient rate\n",
    "covid_summary['inpatient_rate'].plot(kind='bar', ax=axes[2], color=['steelblue', 'coral'])\n",
    "axes[2].set_title('Inpatient Admission Rate')\n",
    "axes[2].set_xlabel('COVID Suspected')\n",
    "axes[2].set_ylabel('Inpatient Rate (%)')\n",
    "axes[2].set_xticklabels(['No', 'Yes'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.4: Statistical Significance Testing\n",
    "\n",
    "Test whether the difference in oxygen saturation between deceased and non-deceased patients is statistically significant.\n",
    "\n",
    "1. State your null hypothesis\n",
    "2. Perform a Mann-Whitney U test (non-parametric alternative to t-test)\n",
    "3. Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the two groups\n",
    "deceased_o2 = covid_df[covid_df['deceased'] == 'Y']['oxygen_saturation_percent'].dropna()\n",
    "survived_o2 = covid_df[covid_df['deceased'] == 'N']['oxygen_saturation_percent'].dropna()\n",
    "\n",
    "print(f\"Deceased - Mean: {deceased_o2.mean():.2f}, Median: {deceased_o2.median():.2f}, n={len(deceased_o2)}\")\n",
    "print(f\"Survived - Mean: {survived_o2.mean():.2f}, Median: {survived_o2.median():.2f}, n={len(survived_o2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Mann-Whitney U test\n",
    "from scipy import stats\n",
    "\n",
    "# Null hypothesis: There is no difference in oxygen saturation between deceased and non-deceased patients\n",
    "# Alternative hypothesis: There is a difference in oxygen saturation between the groups\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(\n",
    "    deceased_o2,\n",
    "    survived_o2,\n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "print(f\"\\nMann-Whitney U Test Results:\")\n",
    "print(f\"U statistic: {u_stat:.2f}\")\n",
    "print(f\"P-value: {p_value:.4e}\")\n",
    "print(f\"\\nSignificance level (α): 0.05\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Result: REJECT the null hypothesis\")\n",
    "    print(\"Interpretation: There IS a statistically significant difference in oxygen saturation\")\n",
    "    print(\"between deceased and non-deceased patients.\")\n",
    "else:\n",
    "    print(\"Result: FAIL TO REJECT the null hypothesis\")\n",
    "    print(\"Interpretation: There is NO statistically significant difference in oxygen saturation\")\n",
    "    print(\"between deceased and non-deceased patients.\")\n",
    "\n",
    "# Effect size (rank biserial correlation)\n",
    "n1, n2 = len(deceased_o2), len(survived_o2)\n",
    "rank_biserial = 1 - (2*u_stat) / (n1 * n2)\n",
    "print(f\"\\nEffect size (rank-biserial correlation): {rank_biserial:.3f}\")\n",
    "print(\"Effect size interpretation: <0.3 small, 0.3-0.5 medium, >0.5 large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** Based on the p-value, is the difference statistically significant at α = 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructor notes:**\n",
    "\n",
    "The p-value is less than 0.05, indicating a statistically significant difference in oxygen saturation between deceased and non-deceased patients. The deceased group has significantly lower oxygen saturation on average.\n",
    "\n",
    "Key teaching points:\n",
    "- Statistical significance (p < 0.05) tells us the difference is unlikely due to chance\n",
    "- Effect size tells us how large/meaningful the difference is\n",
    "- Clinical significance vs. statistical significance - a small difference might be statistically significant with large sample sizes but not clinically meaningful\n",
    "- The Mann-Whitney U test is appropriate here because oxygen saturation may not be normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.5: Condition-Specific Analysis\n",
    "\n",
    "1. Identify which specific conditions are most associated with inpatient admission\n",
    "2. Calculate the inpatient rate for each condition\n",
    "3. Which conditions have the highest inpatient rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge condition-level data with visit type\n",
    "import re\n",
    "\n",
    "cond_rates = (\n",
    "    df\n",
    "    .assign(\n",
    "        condition_item=df['condition'].str.split(r\"\\s*:\\s*\")\n",
    "    )\n",
    "    .explode('condition_item')\n",
    "    .dropna(subset=['condition_item'])\n",
    "    .assign(\n",
    "        condition_item=lambda x: x['condition_item'].str.strip(),\n",
    "        is_inpatient=lambda x: x['visit_type'].str.contains('Inpatient', na=False)\n",
    "    )\n",
    "    .groupby('condition_item')\n",
    "    .agg(\n",
    "        inpatient_rate=('is_inpatient', 'mean'),\n",
    "        total_visits=('visit_occurrence_id', 'count')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "cond_rates['inpatient_rate'] *= 100\n",
    "\n",
    "# Filter to conditions with at least 100 visits for statistical reliability\n",
    "cond_rates_filtered = cond_rates[cond_rates['total_visits'] >= 100]\n",
    "\n",
    "# Top 10 conditions by inpatient rate\n",
    "top_inpatient_conditions = cond_rates_filtered.sort_values('inpatient_rate', ascending=False).head(10)\n",
    "\n",
    "print(\"Top 10 Conditions with Highest Inpatient Admission Rates:\")\n",
    "print(\"(minimum 100 visits)\\n\")\n",
    "print(top_inpatient_conditions.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(top_inpatient_conditions)), top_inpatient_conditions['inpatient_rate'])\n",
    "plt.yticks(range(len(top_inpatient_conditions)), top_inpatient_conditions['condition_item'])\n",
    "plt.xlabel('Inpatient Admission Rate (%)')\n",
    "plt.title('Top 10 Conditions Associated with Inpatient Admission')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Interpretation and Synthesis\n",
    "\n",
    "**Goal:** Move from patterns to meaningful insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1: Synthesis\n",
    "\n",
    "Based on your exploration, write a brief summary (3-5 bullet points) of the most important findings from this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructor notes - Sample answers:**\n",
    "\n",
    "1. **Mortality and oxygen saturation:** There is a strong, statistically significant relationship between low oxygen saturation and mortality. Deceased patients had significantly lower O2 sat levels (mean ~85%) compared to survivors (mean ~95%).\n",
    "\n",
    "2. **Age-related mortality gradient:** Mortality rates increase sharply with age, with elderly patients (65+) having the highest mortality rates. This suggests age is a critical risk factor.\n",
    "\n",
    "3. **COVID impact on admissions:** COVID-suspected patients have higher inpatient admission rates compared to non-COVID patients, indicating more severe illness requiring hospitalization.\n",
    "\n",
    "4. **Comorbidity burden:** Patients with 3+ conditions show worse vital signs on average, suggesting that condition count may be a useful proxy for illness severity.\n",
    "\n",
    "5. **Temporal patterns:** Visit volume shows clear temporal patterns that likely reflect the COVID-19 pandemic timeline and seasonal respiratory illness patterns.\n",
    "\n",
    "6. **Data quality concerns:** Several vital sign measurements contain extreme or implausible values that require investigation (e.g., temperatures >42°C, unrealistic blood pressure readings), suggesting data quality issues that need to be addressed before modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2: Data Limitations\n",
    "\n",
    "What are the key limitations of this dataset that affect what questions we can answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructor notes - Sample limitations:**\n",
    "\n",
    "1. **Missing data:** High rates of missing data in vital signs (~60-70% missing for non-COVID visits) limits our ability to compare COVID vs non-COVID patients on clinical measures.\n",
    "\n",
    "2. **Selection bias:** This is hospital/clinical data, so we only observe patients who sought care. We don't know about patients with mild illness who didn't visit, or population-level incidence.\n",
    "\n",
    "3. **Synthetic data limitations:** As synthetic data, it may not fully capture real-world complexities, rare conditions, or subtle relationships present in actual patient data.\n",
    "\n",
    "4. **Temporal censoring:** We only see visits within a specific time window. Long-term outcomes, readmissions after the study period, or prior history before the data collection started are unknown.\n",
    "\n",
    "5. **Limited treatment information:** We don't have data on treatments received, which makes causal inference about interventions impossible.\n",
    "\n",
    "6. **Measurement variability:** Vital signs may be measured at different times during the visit, with different equipment, and by different staff, introducing measurement error.\n",
    "\n",
    "7. **Condition coding:** Conditions are recorded as free text rather than standardized codes (ICD-10, SNOMED), making systematic analysis more difficult and potentially inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3: Question Classification\n",
    "\n",
    "For each of the following questions, identify which of the seven question types it represents and whether our data can answer it:\n",
    "\n",
    "1. \"What is the average oxygen saturation for COVID-suspected patients?\"\n",
    "2. \"Would providing flu vaccines earlier reduce hospitalizations?\"\n",
    "3. \"Can we predict which patients will be admitted as inpatients based on their vital signs?\"\n",
    "4. \"Is there a significant difference in mortality between age groups?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructor answers:**\n",
    "\n",
    "1. Question type: **Descriptive** | Data support: **YES** - We can calculate this directly from the data\n",
    "\n",
    "2. Question type: **Causal** | Data support: **NO** - This requires an intervention or experiment. Our observational data cannot establish causation, only correlation between vaccination and outcomes\n",
    "\n",
    "3. Question type: **Predictive** | Data support: **PARTIALLY** - We have the features (vital signs) and outcome (admission type), but we'd need to build and validate a model. Missing data is a concern.\n",
    "\n",
    "4. Question type: **Inferential** | Data support: **YES** - We can calculate mortality rates by age group and perform statistical tests to assess if differences are significant\n",
    "\n",
    "**Teaching points:**\n",
    "- Descriptive questions are the easiest to answer - they just require summarizing existing data\n",
    "- Causal questions require experimental or quasi-experimental designs\n",
    "- Predictive questions require building models and proper validation\n",
    "- Inferential questions require statistical testing to determine if patterns generalize beyond our sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.4: Next Steps\n",
    "\n",
    "Based on your EDA, what would be your recommended next steps? Choose from:\n",
    "- Communication and stakeholder alignment\n",
    "- Modeling preparation\n",
    "- Data and process redesign\n",
    "- Goal refinement\n",
    "\n",
    "Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructor notes - Sample answer:**\n",
    "\n",
    "**Recommended next steps:**\n",
    "\n",
    "1. **Data and process redesign (HIGH PRIORITY)**\n",
    "   - Address data quality issues: extreme/implausible vital sign values need investigation\n",
    "   - Standardize condition coding (currently free text, inconsistent)\n",
    "   - Improve vital sign capture for non-COVID patients (currently 60-70% missing)\n",
    "   - Document measurement protocols to reduce variability\n",
    "\n",
    "2. **Communication and stakeholder alignment (HIGH PRIORITY)**\n",
    "   - Share findings about mortality risk factors (age, O2 saturation, comorbidities)\n",
    "   - Discuss data quality concerns with data collection teams\n",
    "   - Align on which questions are most valuable to answer given data limitations\n",
    "   - Clarify whether causal questions (e.g., vaccine effectiveness) are goals - if so, different data collection is needed\n",
    "\n",
    "3. **Goal refinement (MEDIUM PRIORITY)**\n",
    "   - If the goal is prediction (e.g., admission risk), we can proceed with modeling\n",
    "   - If the goal is causal inference, we need to redesign data collection or find alternative approaches\n",
    "   - Clarify the intended use case and success criteria\n",
    "\n",
    "4. **Modeling preparation (LOWER PRIORITY UNTIL DATA QUALITY IMPROVES)**\n",
    "   - Only proceed with modeling after addressing data quality issues\n",
    "   - Develop plan for handling missing vital signs data\n",
    "   - Consider which modeling approach is appropriate given class imbalance (mortality is relatively rare)\n",
    "   - Plan validation strategy\n",
    "\n",
    "**Reasoning:** Data quality issues must be addressed before building models, as \"garbage in, garbage out\" applies. Stakeholder communication is essential to ensure we're solving the right problem and that stakeholders understand data limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 1: Predictive Model Preparation\n",
    "\n",
    "Prepare features for a model that predicts inpatient admission based on vital signs and demographics.\n",
    "\n",
    "1. Select relevant features\n",
    "2. Handle missing values\n",
    "3. Create the target variable\n",
    "4. Check class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive modeling preparation\n",
    "\n",
    "# 1. Select features\n",
    "feature_cols = [\n",
    "    'age_at_visit_years',\n",
    "    'oxygen_saturation_percent',\n",
    "    'respiratory_rate_per_minute',\n",
    "    'heart_rate_bpm',\n",
    "    'body_temperature_c',\n",
    "    'systolic',\n",
    "    'diastolic',\n",
    "    'condition_count',\n",
    "    'gender_source_value',\n",
    "    'age_group'\n",
    "]\n",
    "\n",
    "# 3. Create target variable\n",
    "modeling_df = covid_df.copy()\n",
    "modeling_df['is_inpatient'] = modeling_df['visit_type'].str.contains('Inpatient', na=False).astype(int)\n",
    "\n",
    "# 4. Check class balance\n",
    "print(\"Target Variable Distribution:\")\n",
    "print(modeling_df['is_inpatient'].value_counts())\n",
    "print(f\"\\nInpatient rate: {modeling_df['is_inpatient'].mean()*100:.1f}%\")\n",
    "\n",
    "# Check missing values in features\n",
    "print(\"\\nMissing Values in Features:\")\n",
    "missing_pct = modeling_df[feature_cols].isnull().sum() / len(modeling_df) * 100\n",
    "print(missing_pct[missing_pct > 0])\n",
    "\n",
    "# 2. Handle missing values - simple imputation strategy\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# For numeric columns, impute with median\n",
    "numeric_features = ['age_at_visit_years', 'oxygen_saturation_percent',\n",
    "                   'respiratory_rate_per_minute', 'heart_rate_bpm',\n",
    "                   'body_temperature_c', 'systolic', 'diastolic', 'condition_count']\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "modeling_df[numeric_features] = imputer.fit_transform(modeling_df[numeric_features])\n",
    "\n",
    "print(\"\\nData prepared for modeling!\")\n",
    "print(f\"Total samples: {len(modeling_df)}\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Class balance: {modeling_df['is_inpatient'].value_counts(normalize=True)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2: Condition Co-occurrence\n",
    "\n",
    "Create a co-occurrence matrix showing which conditions tend to appear together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create condition co-occurrence matrix\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Get top 10 most common conditions\n",
    "top_conditions = all_conditions.value_counts().head(10).index.tolist()\n",
    "\n",
    "# Initialize co-occurrence matrix\n",
    "cooc_matrix = pd.DataFrame(0, index=top_conditions, columns=top_conditions)\n",
    "\n",
    "# Count co-occurrences\n",
    "for conditions in df['condition_list'].dropna():\n",
    "    # Clean and filter to top conditions\n",
    "    conditions_clean = [c.strip() for c in conditions if c.strip() in top_conditions]\n",
    "    # Count pairs\n",
    "    for cond1, cond2 in combinations(conditions_clean, 2):\n",
    "        cooc_matrix.loc[cond1, cond2] += 1\n",
    "        cooc_matrix.loc[cond2, cond1] += 1\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cooc_matrix, annot=True, fmt='d', cmap='YlOrRd', square=True, \n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Condition Co-occurrence Matrix (Top 10 Conditions)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop condition pairs:\")\n",
    "# Get upper triangle\n",
    "mask = np.triu(np.ones_like(cooc_matrix, dtype=bool), k=1)\n",
    "pairs = cooc_matrix.where(mask).stack().sort_values(ascending=False)\n",
    "print(pairs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 3: Patient Journey Visualization\n",
    "\n",
    "For patients with multiple visits, visualize their journey over time (conditions and visit types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a patient with multiple visits\n",
    "multi_visit_patients = df.groupby('person_id').size()\n",
    "patient_id = multi_visit_patients[multi_visit_patients >= 3].index[0]  # Get first patient with 3+ visits\n",
    "\n",
    "patient_data = df[df['person_id'] == patient_id].sort_values('visit_start_date')\n",
    "\n",
    "print(f\"Patient Journey for Patient {patient_id}\")\n",
    "print(f\"Total visits: {len(patient_data)}\\n\")\n",
    "\n",
    "# Create timeline visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot 1: Visit types over time\n",
    "visit_types = patient_data['visit_type'].map({'Inpatient Visit': 1, 'Outpatient Visit': 0})\n",
    "ax1.scatter(patient_data['visit_start_date'], visit_types, s=200, c=visit_types, \n",
    "           cmap='RdYlGn_r', alpha=0.7, edgecolors='black', linewidth=2)\n",
    "ax1.set_yticks([0, 1])\n",
    "ax1.set_yticklabels(['Outpatient', 'Inpatient'])\n",
    "ax1.set_ylabel('Visit Type')\n",
    "ax1.set_title(f'Patient Journey: Visit Types Over Time')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 2: Number of conditions over time\n",
    "condition_counts = patient_data['condition_count']\n",
    "ax2.plot(patient_data['visit_start_date'], condition_counts, marker='o', \n",
    "        markersize=10, linewidth=2, color='steelblue')\n",
    "ax2.set_ylabel('Number of Conditions')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_title('Condition Count Over Time')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed visit information\n",
    "print(\"\\nDetailed Visit History:\")\n",
    "for idx, row in patient_data.iterrows():\n",
    "    print(f\"\\nVisit {row['visit_occurrence_id']}:\")\n",
    "    print(f\"  Date: {row['visit_start_date'].date()}\")\n",
    "    print(f\"  Type: {row['visit_type']}\")\n",
    "    print(f\"  Conditions: {row['condition']}\")\n",
    "    print(f\"  Length of stay: {row['length_of_stay']} days\")\n",
    "    if pd.notna(row['oxygen_saturation_percent']):\n",
    "        print(f\"  O2 Saturation: {row['oxygen_saturation_percent']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: Key EDA Concepts\n",
    "\n",
    "### The EDA Lifecycle\n",
    "1. Clarify the analytical goal\n",
    "2. Understand data provenance, structure, and integrity\n",
    "3. Explore (distributional, relational, structural, comparative)\n",
    "4. Interpret findings and refine hypotheses\n",
    "5. Translate results into next steps\n",
    "\n",
    "### The Seven Question Types\n",
    "1. Descriptive — What happened?\n",
    "2. Exploratory — What patterns exist?\n",
    "3. Inferential — Does this generalize?\n",
    "4. Predictive — What will happen?\n",
    "5. Prescriptive — What should we do?\n",
    "6. Causal — What if we intervene?\n",
    "7. Mechanistic — What process produces this?\n",
    "\n",
    "### The Four Exploration Dimensions\n",
    "1. **Distributional** — Individual variable shape, outliers, missingness\n",
    "2. **Relational** — Correlations, interactions between variables\n",
    "3. **Structural** — Temporal, hierarchical, sequential patterns\n",
    "4. **Comparative** — Differences across groups and time periods\n",
    "\n",
    "### The Seven Core Principles\n",
    "1. Let the data surprise you\n",
    "2. Multiple encodings, multiple perspectives\n",
    "3. Segment early, segment often\n",
    "4. Explicitly check assumptions\n",
    "5. Expect heterogeneity and drift\n",
    "6. Distinguish signal from artifact\n",
    "7. Document hypotheses and alternative explanations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
